#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç®€åŒ–ç‰ˆå¤åˆè‰ç¨¿ç”Ÿæˆå™¨
ç›´æ¥æ›¿æ¢æ¨¡æ¿ä¸­çš„å¿…è¦éƒ¨åˆ†ï¼Œæœ€å°åŒ–ä¿®æ”¹
"""

# ================== é…ç½®å¼€å…³ ==================
# å­—å¹•è°ƒè¯•æ¨¡å¼ - å¼€å¯æ—¶åªç”Ÿæˆå‰10ä¸ªå­—å¹•ï¼Œç”¨äºæµ‹è¯•
SUBTITLE_DEBUG_MODE = True

# ä¸­æ–‡å­—å¹•å¼€å…³ - é»˜è®¤å…³é—­ä¸­æ–‡å­—å¹•
ENABLE_CHINESE_SUBTITLES = False

# è‹±æ–‡å­—å¹•å¼€å…³ - é»˜è®¤å¼€å¯è‹±æ–‡å­—å¹•
ENABLE_ENGLISH_SUBTITLES = True

# è°ƒè¯•æ¨¡å¼ä¸‹çš„å­—å¹•æ•°é‡é™åˆ¶
DEBUG_SUBTITLE_LIMIT = 1

# ================== é€Ÿåº¦æ§åˆ¶é…ç½® ==================
# ç›®æ ‡è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰- æ§åˆ¶æœ€ç»ˆè§†é¢‘åœ¨1åˆ†é’Ÿå†…
TARGET_DURATION_SECONDS = 60

# æœ€å¤§æ’­æ”¾é€Ÿåº¦å€æ•° - é™åˆ¶æœ€å¤§é€Ÿåº¦ä¸º2.5å€
MAX_SPEED_FACTOR = 1.5
# ================================================

import json
import os
import sys
import uuid
import shutil
import copy
import re
import logging
from pathlib import Path
from pydub import AudioSegment as PydubAudioSegment
from typing import List, Dict, Optional
from data_models import StoryDialogue, StoryContent

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(filename)s:%(lineno)d - %(message)s'
)
logger = logging.getLogger(__name__)

# å­—å¹•æ¨¡æ¿åŠ è½½å‡½æ•°
def load_subtitle_templates_from_draft(template_file):
    """ä»è‰ç¨¿æ¨¡æ¿æ–‡ä»¶ä¸­åŠ è½½å­—å¹•æ¨¡æ¿"""
    try:
        with open(template_file, 'r', encoding='utf-8') as f:
            template_data = json.load(f)

        # ä»åµŒå¥—è‰ç¨¿ä¸­è·å–å­—å¹•æ¨¡æ¿
        nested_draft = template_data['materials']['drafts'][0]['draft']
        texts_templates = nested_draft['materials'].get('texts', [])

        # è·å–å­—å¹•è½¨é“æ¨¡æ¿
        text_tracks = [t for t in nested_draft['tracks'] if t.get('type') == 'text']
        track_template = text_tracks[0] if text_tracks else None

        return texts_templates, track_template
    except Exception as e:
        logger.error(f"âŒ ä»è‰ç¨¿æ¨¡æ¿åŠ è½½å­—å¹•å¤±è´¥: {e}")
        return [], None

# é»˜è®¤é…ç½®å¸¸é‡
DEFAULT_TEMPLATE_FILE = "./templates/draft_content_fuhe.json"
DEFAULT_TEMPLATE_SETTINGS= "./templates/draft_settings"
DEFAULT_TEMPLATE_INFO_FILE = "./templates/draft_meta_info.json"
DEFAULT_OUTPUT_DIR = "./output/draft_folder"
DEFAULT_SCALE_X = 1.0
DEFAULT_SCALE_Y = 1.0
DEFAULT_GAP = 0
DEFAULT_BLUR_STRENGTH = 0.375
DEFAULT_BACKGROUND_AUDIO_PATH = "./templates/jazz.wav"

# æ•…äº‹å¯¹è±¡ç±»å·²ä» data_models.py å¯¼å…¥


def time_to_microseconds(time_str):
    """å°†æ—¶é—´å­—ç¬¦ä¸²è½¬æ¢ä¸ºå¾®ç§’"""
    if isinstance(time_str, (int, float)):
        return int(time_str * 1000000)

    # å¤„ç†SRTæ ¼å¼çš„æ—¶é—´å­—ç¬¦ä¸² (HH:MM:SS,mmm)
    if ',' in time_str:
        time_part, ms_part = time_str.split(',')
        parts = time_part.split(':')
        if len(parts) == 3:
            hours, minutes, seconds = parts
            total_seconds = int(hours) * 3600 + int(minutes) * 60 + int(seconds) + int(ms_part) / 1000.0
        else:
            total_seconds = float(time_part) + int(ms_part) / 1000.0
    else:
        parts = time_str.split(':')
        if len(parts) == 3:
            hours, minutes, seconds = parts
            total_seconds = int(hours) * 3600 + int(minutes) * 60 + float(seconds)
        else:
            total_seconds = float(time_str)

    return int(total_seconds * 1000000)


def get_audio_duration(audio_path):
    """è·å–éŸ³é¢‘æ–‡ä»¶æ—¶é•¿ï¼ˆç§’ï¼‰"""
    try:
        audio = PydubAudioSegment.from_file(audio_path)
        return len(audio) / 1000.0
    except Exception as e:
        logger.error(f"æ— æ³•è·å–éŸ³é¢‘æ—¶é•¿ {audio_path}: {e}")
        return 1.0  # è¿”å›é»˜è®¤æ—¶é•¿é¿å…é™¤é›¶é”™è¯¯




def calculate_speed_factor(original_duration_seconds):
    """
    æ ¹æ®åŸå§‹æ—¶é•¿è®¡ç®—æ’­æ”¾é€Ÿåº¦ï¼Œç¡®ä¿ç›®æ ‡æ—¶é•¿åœ¨1åˆ†é’Ÿå†…ï¼Œæœ€å¤§é€Ÿåº¦2.5å€

    Args:
        original_duration_seconds: åŸå§‹è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰

    Returns:
        float: è®¡ç®—å‡ºçš„æ’­æ”¾é€Ÿåº¦å€æ•°
    """
    if original_duration_seconds <= 0:
        return 1.0

    # æŒ‰ç›®æ ‡æ—¶é—´è®¡ç®—éœ€è¦çš„é€Ÿåº¦
    required_speed = original_duration_seconds / TARGET_DURATION_SECONDS

    # é™åˆ¶åœ¨æœ€å¤§é€Ÿåº¦ä»¥å†…
    final_speed = min(required_speed, MAX_SPEED_FACTOR)

    # ç¡®ä¿é€Ÿåº¦è‡³å°‘ä¸º1.0ï¼ˆä¸èƒ½æ…¢äºåŸé€Ÿï¼‰
    final_speed = max(final_speed, 1.0)

    logger.info(f"åŸå§‹æ—¶é•¿: {original_duration_seconds:.1f}s")
    logger.info(f"ç›®æ ‡æ—¶é•¿: {TARGET_DURATION_SECONDS:.1f}s")
    logger.info(f"æŒ‰æ—¶é—´è®¡ç®—éœ€è¦é€Ÿåº¦: {required_speed:.2f}x")
    logger.info(f"æœ€ç»ˆä½¿ç”¨é€Ÿåº¦: {final_speed:.2f}x")
    logger.info(f"å®é™…è¾“å‡ºæ—¶é•¿: {original_duration_seconds / final_speed:.1f}s")

    return final_speed


def generate_uuid():
    """ç”ŸæˆUUID"""
    return str(uuid.uuid4()).upper()


class VideoMaterial:
    """è§†é¢‘ææ–™å¯¹è±¡"""
    def __init__(self, material_id, material_name, path, duration, crop):
        self.id = material_id
        self.material_name = material_name
        self.path = path
        self.duration = duration
        self.crop = crop

class AudioMaterial:
    """éŸ³é¢‘ææ–™å¯¹è±¡"""
    def __init__(self, material_id, name, path, duration, audio_type="sound"):
        self.id = material_id
        self.name = name
        self.path = path
        self.duration = duration
        self.type = audio_type

class VideoSegment:
    """è§†é¢‘ç‰‡æ®µå¯¹è±¡"""
    def __init__(self, segment_id, material_id, source_timerange, target_timerange, speed, scale, volume=0.0):
        self.id = segment_id
        self.material_id = material_id
        self.source_timerange = source_timerange
        self.target_timerange = target_timerange
        self.speed = speed
        self.clip = {"scale": scale}
        self.volume = volume

class AudioSegment:
    """éŸ³é¢‘ç‰‡æ®µå¯¹è±¡"""
    def __init__(self, segment_id, material_id, source_timerange, target_timerange, speed=1.0, volume=1.0):
        self.id = segment_id
        self.material_id = material_id
        self.source_timerange = source_timerange
        self.target_timerange = target_timerange
        self.speed = speed
        self.volume = volume


class DraftGenerator:
    """è‰ç¨¿ç”Ÿæˆå™¨ç±»"""

    def __init__(self,
                 template_file: str = DEFAULT_TEMPLATE_FILE,
                 output_dir: str = DEFAULT_OUTPUT_DIR,
                 scale_x: float = DEFAULT_SCALE_X,
                 scale_y: float = DEFAULT_SCALE_Y,
                 gap: float = DEFAULT_GAP,
                 blur_strength: float = DEFAULT_BLUR_STRENGTH,
                 background_audio_path: Optional[str] = DEFAULT_BACKGROUND_AUDIO_PATH):
        self.template_file = template_file
        self.output_dir = output_dir
        self.scale_x = scale_x
        self.scale_y = scale_y
        self.gap = gap
        self.blur_strength = blur_strength
        self.background_audio_path = background_audio_path


    def create_nested_draft_simple(self, story: StoryContent, video_path: str):
        """åˆ›å»ºç®€åŒ–çš„åµŒå¥—è‰ç¨¿ - æ”¯æŒä¸€ä¸ªéŸ³é¢‘å¯¹åº”å¤šä¸ªè§†é¢‘ç‰‡æ®µ"""
        # è®¡ç®—æ€»æ—¶é•¿
        current_time = 0.0
        segments_info = []

        for dialogue in story.dialogue_list:
            # å¦‚æœæ²¡æœ‰è¯­éŸ³æ–‡ä»¶ï¼Œè·³è¿‡ï¼ˆæˆ–åˆ›å»ºè™šæ‹ŸéŸ³é¢‘ç”¨äºå­—å¹•å¤„ç†ï¼‰
            if not dialogue.audio_path:
                logger.warning(f"âš ï¸ Dialogue {dialogue.index} æ²¡æœ‰éŸ³é¢‘æ–‡ä»¶ï¼Œè·³è¿‡")
                continue

            current_time += self.gap

            # ğŸ”‘ è·å–éŸ³é¢‘æ—¶é•¿
            audio_duration = get_audio_duration(dialogue.audio_path)

            # ğŸ”‘ è®¡ç®—æ‰€æœ‰è§†é¢‘ç‰‡æ®µçš„æ€»æ—¶é•¿
            total_video_duration = 0.0
            for video_seg in dialogue.video_segments:
                start_seconds = time_to_microseconds(video_seg['start']) / 1000000.0
                end_seconds = time_to_microseconds(video_seg['end']) / 1000000.0
                total_video_duration += (end_seconds - start_seconds)

            if total_video_duration == 0:
                logger.warning(f"âš ï¸ Dialogue {dialogue.index} çš„è§†é¢‘ç‰‡æ®µæ€»æ—¶é•¿ä¸º0ï¼Œè·³è¿‡")
                continue

            # ğŸ”‘ è®¡ç®—è§†é¢‘é€Ÿåº¦ï¼ˆä½¿è§†é¢‘æ€»æ—¶é•¿åŒ¹é…éŸ³é¢‘æ—¶é•¿ï¼‰
            video_speed = total_video_duration / max(audio_duration, 0.1)
            logger.info(f"  ğŸ“Š Dialogue {dialogue.index}: éŸ³é¢‘={audio_duration:.2f}s, è§†é¢‘={total_video_duration:.2f}s, é€Ÿåº¦={video_speed:.2f}x")

            # ğŸ”‘ ä¸ºæ¯ä¸ªè§†é¢‘ç‰‡æ®µåˆ›å»º segment_info
            for video_seg_idx, video_seg in enumerate(dialogue.video_segments):
                source_start_seconds = time_to_microseconds(video_seg['start']) / 1000000.0
                source_end_seconds = time_to_microseconds(video_seg['end']) / 1000000.0
                source_duration = source_end_seconds - source_start_seconds

                # è®¡ç®—è°ƒæ•´åçš„è§†é¢‘ç‰‡æ®µæ—¶é•¿ï¼ˆåº”ç”¨é€Ÿåº¦åï¼‰
                adjusted_duration = source_duration / video_speed

                segments_info.append({
                    'target_start': current_time,
                    'audio_duration': adjusted_duration,  # è°ƒæ•´åçš„æ—¶é•¿
                    'source_start': source_start_seconds,
                    'source_duration': source_duration,
                    'audio_path': dialogue.audio_path,  # å…±äº«åŒä¸€éŸ³é¢‘
                    'video_speed': video_speed,  # ğŸ†• è§†é¢‘é€Ÿåº¦
                    'dialogue_obj': dialogue,
                    'video_seg_idx': video_seg_idx,  # å½“å‰æ˜¯ç¬¬å‡ ä¸ªè§†é¢‘ç‰‡æ®µ
                    'total_video_segs': len(dialogue.video_segments)  # æ€»å…±å¤šå°‘ä¸ªè§†é¢‘ç‰‡æ®µ
                })

                current_time += adjusted_duration

        total_duration = int(current_time * 1000000)

        # ç”Ÿæˆææ–™å’Œç‰‡æ®µå¯¹è±¡
        video_materials = []
        audio_materials = []
        video_segments = []
        audio_segments = []

        crop_config = {
            "lower_left_x": 0.13364055299539157,
            "lower_left_y": 0.8648233486943162,
            "lower_right_x": 0.8179723502304148,
            "lower_right_y": 0.8648233486943162,
            "upper_left_x": 0.13364055299539157,
            "upper_left_y": 0.0,
            "upper_right_x": 0.8179723502304148,
            "upper_right_y": 0.0
        }

        # ğŸ”‘ éŸ³é¢‘ææ–™å»é‡ï¼ˆå¤šä¸ªè§†é¢‘ç‰‡æ®µå…±äº«åŒä¸€éŸ³é¢‘ï¼‰
        audio_path_to_material_id = {}
        audio_path_to_info = {}  # å­˜å‚¨æ¯ä¸ªéŸ³é¢‘çš„ç¬¬ä¸€ä¸ªç‰‡æ®µä¿¡æ¯

        for info in segments_info:
            if info['audio_path'] is None:
                continue

            # è§†é¢‘ææ–™ï¼ˆæ¯ä¸ªè§†é¢‘ç‰‡æ®µç‹¬ç«‹ï¼‰
            video_id = generate_uuid()
            video_file_name = os.path.basename(video_path)

            video_material = VideoMaterial(
                material_id=video_id,
                material_name=video_file_name,
                path=f"##_draftpath_placeholder_0E685133-18CE-45ED-8CB8-2904A212EC80_##/materials/{video_file_name}",
                duration=44733333,
                crop=crop_config
            )
            video_materials.append(video_material)

            # ğŸ”‘ éŸ³é¢‘ææ–™å»é‡
            if info['audio_path'] not in audio_path_to_material_id:
                audio_id = generate_uuid()
                audio_path_to_material_id[info['audio_path']] = audio_id
                audio_path_to_info[info['audio_path']] = info

                # è·å–å®Œæ•´éŸ³é¢‘æ—¶é•¿
                full_audio_duration = get_audio_duration(info['audio_path'])

                audio_material = AudioMaterial(
                    material_id=audio_id,
                    name=os.path.basename(info['audio_path']),
                    path=f"##_draftpath_placeholder_0E685133-18CE-45ED-8CB8-2904A212EC80_##/materials/{os.path.basename(info['audio_path'])}",
                    duration=int(full_audio_duration * 1000000),
                    audio_type="sound"
                )
                audio_materials.append(audio_material)
                logger.info(f"  ğŸµ åˆ›å»ºéŸ³é¢‘ææ–™: {os.path.basename(info['audio_path'])}")
            else:
                audio_id = audio_path_to_material_id[info['audio_path']]

            # åˆ›å»ºè§†é¢‘ç‰‡æ®µå¯¹è±¡
            video_segment = VideoSegment(
                segment_id=generate_uuid(),
                material_id=video_id,
                source_timerange={
                    "duration": int(info['source_duration'] * 1000000),
                    "start": int(info['source_start'] * 1000000)
                },
                target_timerange={
                    "duration": int(info['audio_duration'] * 1000000),
                    "start": int(info['target_start'] * 1000000)
                },
                speed=info['video_speed'],  # ğŸ†• ä½¿ç”¨è®¡ç®—çš„é€Ÿåº¦
                scale={"x": self.scale_x, "y": self.scale_y},
                volume=0.0
            )
            video_segments.append(video_segment)

            # ğŸ”‘ éŸ³é¢‘ç‰‡æ®µï¼ˆåªåœ¨ç¬¬ä¸€ä¸ªè§†é¢‘ç‰‡æ®µæ—¶åˆ›å»ºï¼‰
            if info['video_seg_idx'] == 0:
                full_audio_duration = get_audio_duration(info['audio_path'])
                audio_segment = AudioSegment(
                    segment_id=generate_uuid(),
                    material_id=audio_id,
                    source_timerange={
                        "duration": int(full_audio_duration * 1000000),
                        "start": 0
                    },
                    target_timerange={
                        "duration": int(full_audio_duration * 1000000),
                        "start": int(info['target_start'] * 1000000)
                    },
                    speed=1.0,
                    volume=1.0
                )
                audio_segments.append(audio_segment)
                logger.info(f"  ğŸ¤ åˆ›å»ºéŸ³é¢‘ç‰‡æ®µ: dialogue {info['dialogue_obj'].index}")

        # ç”Ÿæˆå­—å¹•ææ–™å’Œç‰‡æ®µ
        subtitle_materials, subtitle_segments, subtitle_tracks = self._generate_subtitles(segments_info)

        return {
            'duration': total_duration,
            'video_materials': video_materials,
            'audio_materials': audio_materials,
            'video_segments': video_segments,
            'audio_segments': audio_segments,
            'subtitle_materials': subtitle_materials,
            'subtitle_segments': subtitle_segments,
            'subtitle_tracks': subtitle_tracks
        }

    def _generate_subtitles(self, segments_info):
        """ç”Ÿæˆå­—å¹•ææ–™å’Œç‰‡æ®µ - åŸºäºæ¨¡æ¿å¤åˆ¶æ›¿æ¢"""
        subtitle_materials = []
        subtitle_tracks = []

        # ä»è‰ç¨¿æ¨¡æ¿æ–‡ä»¶ä¸­åŠ è½½å­—å¹•æ¨¡æ¿
        material_templates, track_template = load_subtitle_templates_from_draft(self.template_file)
        if not material_templates or not track_template:
            logger.warning("âŒ æ— å­—å¹•æ¨¡æ¿ï¼Œè·³è¿‡å­—å¹•ç”Ÿæˆ")
            return [], [], []

        logger.info(f"âœ“ åŠ è½½å­—å¹•æ¨¡æ¿: {len(material_templates)} ä¸ªææ–™æ¨¡æ¿")

        # ç¡®å®šå¤„ç†çš„å­—å¹•æ•°é‡
        process_count = len(segments_info)
        if SUBTITLE_DEBUG_MODE:
            process_count = min(DEBUG_SUBTITLE_LIMIT, len(segments_info))
            logger.info(f"ğŸ”§ å­—å¹•è°ƒè¯•æ¨¡å¼ï¼šåªå¤„ç†å‰ {process_count} ä¸ªå­—å¹•")

        # åˆ›å»ºå­—å¹•è½¨é“ï¼ˆåŸºäºæ¨¡æ¿ï¼‰
        subtitle_track = copy.deepcopy(track_template)
        subtitle_track['id'] = generate_uuid()
        subtitle_track['segments'] = []

        # åŸºäºéŸ³é¢‘ç‰‡æ®µçš„target_startæ¥å®šä½å­—å¹•æ—¶é—´ï¼ˆä¸å†ä½¿ç”¨ç´¯ç§¯æ—¶é—´ï¼‰

        for i, info in enumerate(segments_info[:process_count]):
            # åªåœ¨ç¬¬ä¸€ä¸ªè§†é¢‘ç‰‡æ®µæ—¶å¤„ç†å­—å¹•ï¼ˆæŒ‰éŸ³é¢‘å…³ç³»ç”Ÿæˆï¼Œé¿å…é‡å¤ï¼‰
            if info['video_seg_idx'] != 0:
                continue

            dialogue_obj = info['dialogue_obj']

            # åªå¤„ç†æœ‰SRTæ–‡ä»¶çš„å¯¹è¯ï¼ŒåŠ è½½SRTæ–‡ä»¶è·å–é€å­—å­—å¹•
            if not dialogue_obj.srt_path or not os.path.exists(dialogue_obj.srt_path):
                logger.warning(f"âš ï¸ è·³è¿‡å¯¹è¯ {dialogue_obj.index}ï¼šæ²¡æœ‰SRTæ–‡ä»¶")
                continue

            srt_subtitles = self._load_srt_file(dialogue_obj.srt_path)
            if not srt_subtitles:
                logger.warning(f"âš ï¸ è·³è¿‡å¯¹è¯ {dialogue_obj.index}ï¼šSRTæ–‡ä»¶ä¸ºç©º")
                continue

            # è·å–å½“å‰éŸ³é¢‘ç‰‡æ®µçš„ç›®æ ‡èµ·å§‹æ—¶é—´ï¼ˆå¾®ç§’ï¼‰
            audio_target_start = int(info['target_start'] * 1000000)

            for j, subtitle_entry in enumerate(srt_subtitles):
                # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ¨¡æ¿ï¼ˆåªæœ‰è‹±æ–‡å­—å¹•é€»è¾‘ï¼‰
                template_idx = 0

                # åˆ›å»ºå­—å¹•ææ–™ï¼ˆåŸºäºæ¨¡æ¿å¤åˆ¶ï¼‰
                subtitle_material = copy.deepcopy(material_templates[template_idx])
                subtitle_material['id'] = generate_uuid()

                # è§£æå¹¶ä¿®æ”¹contentä¸­çš„textå­—æ®µ
                try:
                    content_obj = json.loads(subtitle_material['content'])

                    # å»é™¤æ ‡ç‚¹ç¬¦å·å¹¶æ¸…ç†æ–‡æœ¬
                    clean_text = self._clean_subtitle_text(subtitle_entry['text'])
                    if not clean_text:  # å¦‚æœæ¸…ç†åä¸ºç©ºï¼Œè·³è¿‡
                        continue

                    # è®¾ç½®æ–‡æœ¬å†…å®¹
                    content_obj['text'] = clean_text

                    # æ ¹æ®æ–‡æœ¬é•¿åº¦è®¡ç®—range
                    text_length = len(clean_text)
                    if 'styles' in content_obj and content_obj['styles']:
                        for style in content_obj['styles']:
                            if 'range' in style:
                                style['range'] = [0, text_length]

                    subtitle_material['content'] = json.dumps(content_obj, ensure_ascii=False)
                except Exception as e:
                    logger.warning(f"âš ï¸ å­—å¹•å†…å®¹è§£æå¤±è´¥: {e}")
                    continue

                subtitle_materials.append(subtitle_material)

                # åˆ›å»ºå­—å¹•ç‰‡æ®µï¼ˆåŸºäºæ¨¡æ¿å¤åˆ¶ï¼‰
                if track_template['segments']:
                    segment_template = track_template['segments'][0]
                    subtitle_segment = copy.deepcopy(segment_template)
                    subtitle_segment['id'] = generate_uuid()
                    subtitle_segment['material_id'] = subtitle_material['id']

                    # è®¡ç®—æ—¶é—´åç§»ï¼ˆå¾®ç§’ï¼‰
                    srt_start_ms = self._srt_time_to_microseconds(subtitle_entry['start'])
                    srt_duration_ms = self._srt_time_to_microseconds(subtitle_entry['end']) - srt_start_ms

                    # åŸºäºéŸ³é¢‘ç‰‡æ®µçš„ç›®æ ‡æ—¶é—´è¿›è¡Œå®šä½
                    adjusted_start = audio_target_start + srt_start_ms

                    # æ›´æ–°ç‰‡æ®µæ—¶é—´
                    subtitle_segment['target_timerange'] = {
                        'start': adjusted_start,
                        'duration': srt_duration_ms
                    }
                    subtitle_segment['source_timerange'] = {
                        'start': 0,
                        'duration': srt_duration_ms
                    }

                    subtitle_track['segments'].append(subtitle_segment)

            # å­—å¹•æ—¶é—´å·²åŸºäºéŸ³é¢‘ç‰‡æ®µçš„target_startè¿›è¡Œå®šä½ï¼Œæ— éœ€ç´¯ç§¯æ—¶é—´

        if subtitle_track['segments']:
            subtitle_tracks.append(subtitle_track)

        logger.info(f"âœ“ ç”Ÿæˆå­—å¹•: {len(subtitle_materials)} ä¸ªææ–™, {len(subtitle_tracks)} ä¸ªè½¨é“")
        return subtitle_materials, [], subtitle_tracks

    def _load_srt_file(self, srt_path):
        """åŠ è½½SRTæ–‡ä»¶å¹¶è§£æ"""
        try:
            with open(srt_path, 'r', encoding='utf-8') as f:
                content = f.read().strip()

            entries = []
            for block in content.split('\n\n'):
                lines = block.strip().split('\n')
                if len(lines) >= 3:
                    # è§£ææ—¶é—´
                    time_line = lines[1]
                    if ' --> ' in time_line:
                        start_time, end_time = time_line.split(' --> ')
                        # æ–‡æœ¬å†…å®¹
                        text = '\n'.join(lines[2:])
                        entries.append({
                            'start': start_time.strip(),
                            'end': end_time.strip(),
                            'text': text.strip()
                        })
            return entries
        except Exception as e:
            logger.error(f"âŒ åŠ è½½SRTæ–‡ä»¶å¤±è´¥ {srt_path}: {e}")
            return []

    def _srt_time_to_microseconds(self, srt_time):
        """å°†SRTæ—¶é—´æ ¼å¼è½¬æ¢ä¸ºå¾®ç§’"""
        try:
            time_part, milliseconds = srt_time.split(',')
            hours, minutes, seconds = map(int, time_part.split(':'))
            total_microseconds = (hours * 3600 + minutes * 60 + seconds) * 1000000 + int(milliseconds) * 1000
            return total_microseconds
        except Exception as e:
            logger.error(f"âŒ æ—¶é—´è½¬æ¢é”™è¯¯: {e}")
            return 0

    def _clean_subtitle_text(self, text):
        """æ¸…ç†å­—å¹•æ–‡æœ¬ï¼Œå»é™¤æ ‡ç‚¹ç¬¦å·å’Œå¤šä½™ç©ºæ ¼"""
        import re

        # å»é™¤å¸¸è§æ ‡ç‚¹ç¬¦å·
        punctuation_pattern = r'[.,!?;:\'"\-\(\)\[\]{}]'
        clean_text = re.sub(punctuation_pattern, '', text)

        # å»é™¤å¤šä½™ç©ºæ ¼å¹¶è½¬æ¢ä¸ºå•ä¸ªç©ºæ ¼
        clean_text = re.sub(r'\s+', ' ', clean_text)

        # å»é™¤é¦–å°¾ç©ºæ ¼
        clean_text = clean_text.strip()

        return clean_text

    def _format_title_text(self, title):
        """æ ¼å¼åŒ–æ ‡é¢˜æ–‡æœ¬ï¼ŒæŒ‰ç©ºæ ¼åˆ‡åˆ†ï¼Œè¶…è¿‡20å­—ç¬¦æ¢è¡Œ"""
        if not title:
            return ""
        non_tag_title = title.split('#')[0].strip()
        words = non_tag_title.split(' ')
        lines = []
        current_line = []
        current_length = 0

        for word in words:
            # å¦‚æœåŠ ä¸Šè¿™ä¸ªè¯ä¼šè¶…è¿‡20å­—ç¬¦ï¼Œå¼€å§‹æ–°è¡Œ
            word_length = len(word)
            if current_length > 0:  # ä¸æ˜¯ç¬¬ä¸€ä¸ªè¯ï¼Œéœ€è¦åŠ ç©ºæ ¼
                test_length = current_length + 1 + word_length
            else:
                test_length = word_length

            if test_length > 20 and current_line:
                # å½“å‰è¡Œå·²æœ‰å†…å®¹ä¸”ä¼šè¶…é•¿ï¼Œå¼€å§‹æ–°è¡Œ
                lines.append(' '.join(current_line))
                current_line = [word]
                current_length = word_length
            else:
                # å¯ä»¥åŠ åˆ°å½“å‰è¡Œ
                current_line.append(word)
                current_length = test_length

        # åŠ ä¸Šæœ€åä¸€è¡Œ
        if current_line:
            lines.append(' '.join(current_line))

        return '\n'.join(lines)

    def _add_subtitle_tracks(self, nested_draft, nested_data):
        """æ·»åŠ å­—å¹•è½¨é“åˆ°åµŒå¥—è‰ç¨¿ - æ¸…ç†æ—§å­—å¹•ï¼Œåœ¨åŸè½¨é“ä¸Šæ·»åŠ æ–°å­—å¹•"""
        if 'subtitle_materials' not in nested_data or 'subtitle_tracks' not in nested_data:
            return

        # 1. æ¸…ç†æ—§çš„å­—å¹•ææ–™
        if 'texts' not in nested_draft['materials']:
            nested_draft['materials']['texts'] = []
        else:
            logging.info(f"ğŸ§¹ æ¸…ç†æ—§å­—å¹•ææ–™: {len(nested_draft['materials']['texts'])} ä¸ª")
            nested_draft['materials']['texts'].clear()

        # 2. æ·»åŠ æ–°çš„å­—å¹•ææ–™
        for subtitle_material in nested_data['subtitle_materials']:
            nested_draft['materials']['texts'].append(subtitle_material)

        # 3. æ¸…ç†å¹¶æ›´æ–°å­—å¹•è½¨é“
        # æ‰¾åˆ°ç°æœ‰çš„å­—å¹•è½¨é“ï¼ˆtypeä¸ºtextçš„è½¨é“ï¼‰
        text_tracks = [track for track in nested_draft['tracks'] if track.get('type') == 'text']

        if text_tracks:
            # æ¸…ç†ç°æœ‰å­—å¹•è½¨é“çš„segments
            for track in text_tracks:
                old_segments_count = len(track.get('segments', []))
                logging.info(f"ğŸ§¹ æ¸…ç†è½¨é“ {track.get('id', '')[:8]}... çš„æ—§ç‰‡æ®µ: {old_segments_count} ä¸ª")
                track['segments'] = []

            # å°†æ–°å­—å¹•ç‰‡æ®µæ·»åŠ åˆ°ç¬¬ä¸€ä¸ªå­—å¹•è½¨é“
            if nested_data['subtitle_tracks'] and nested_data['subtitle_tracks'][0]['segments']:
                target_track = text_tracks[0]
                new_segments = nested_data['subtitle_tracks'][0]['segments']
                target_track['segments'].extend(new_segments)
                logging.info(f"âœ“ åœ¨åŸè½¨é“ä¸Šæ·»åŠ äº† {len(new_segments)} ä¸ªæ–°å­—å¹•ç‰‡æ®µ")
        else:
            # å¦‚æœæ²¡æœ‰ç°æœ‰å­—å¹•è½¨é“ï¼Œç›´æ¥æ·»åŠ æ–°è½¨é“
            for subtitle_track in nested_data['subtitle_tracks']:
                nested_draft['tracks'].append(subtitle_track)
            logging.info(f"âœ“ æ·»åŠ äº† {len(nested_data['subtitle_tracks'])} ä¸ªæ–°å­—å¹•è½¨é“")

        logging.info(f"âœ“ å­—å¹•æ›´æ–°å®Œæˆ: {len(nested_data['subtitle_materials'])} ä¸ªææ–™")

    def _update_main_title_text(self, draft, story_title, total_duration):
        """æ›´æ–°ä¸»è½´çš„æ ‡é¢˜æ–‡æœ¬å†…å®¹å’Œæ—¶é•¿"""
        try:
            # æ ¼å¼åŒ–æ ‡é¢˜æ–‡æœ¬
            formatted_title = self._format_title_text(story_title)

            # æ›´æ–°ä¸»è½´æ–‡æœ¬ææ–™
            main_texts = draft['materials'].get('texts', [])
            if main_texts:
                text_material = main_texts[0]
                content = text_material.get('content', '')
                if content:
                    content_obj = json.loads(content)
                    content_obj['text'] = formatted_title

                    # æ ¹æ®æ–‡æœ¬é•¿åº¦è®¡ç®—range
                    text_length = len(formatted_title)
                    if 'styles' in content_obj and content_obj['styles']:
                        for style in content_obj['styles']:
                            if 'range' in style:
                                style['range'] = [0, text_length]

                    text_material['content'] = json.dumps(content_obj, ensure_ascii=False)
                    logging.info(f"âœ“ æ›´æ–°ä¸»è½´æ ‡é¢˜æ–‡æœ¬: \"{formatted_title.replace(chr(10), ' / ')}\"")

            # æ›´æ–°ä¸»è½´æ–‡æœ¬è½¨é“çš„æ—¶é•¿
            main_tracks = [t for t in draft.get('tracks', []) if t.get('type') == 'text']
            if main_tracks:
                text_track = main_tracks[0]
                segments = text_track.get('segments', [])
                if segments:
                    segment = segments[0]
                    # ç¡®ä¿ timerange å¯¹è±¡å­˜åœ¨
                    if 'target_timerange' in segment and segment['target_timerange'] is not None:
                        segment['target_timerange']['duration'] = total_duration
                    if 'source_timerange' in segment and segment['source_timerange'] is not None:
                        segment['source_timerange']['duration'] = total_duration
                    logging.info(f"âœ“ æ›´æ–°ä¸»è½´æ ‡é¢˜æ—¶é•¿: {total_duration / 1000000:.3f}ç§’")

        except Exception as e:
            logging.info(f"âš ï¸ æ›´æ–°ä¸»è½´æ ‡é¢˜å¤±è´¥: {e}")

    def generate_from_file(self, enhanced_srt_file: str, video_path: str) -> str:
        """ä»æ–‡ä»¶ç”Ÿæˆè‰ç¨¿ï¼Œå…ˆè½¬æ¢ä¸º StoryContent å¯¹è±¡"""
        logging.info(f"å¼€å§‹ä»æ–‡ä»¶ç”Ÿæˆè‰ç¨¿: {enhanced_srt_file}")

        # è¯»å–æ–‡ä»¶æ•°æ®
        with open(enhanced_srt_file, 'r', encoding='utf-8') as f:
            srt_data = json.load(f)

        # è½¬æ¢ä¸º StoryContent å¯¹è±¡
        if isinstance(srt_data, list) and len(srt_data) > 0:
            # å¤„ç† AI åˆ†æåçš„æ ¼å¼ï¼ˆåŒ…å« story_title ç­‰å­—æ®µï¼‰
            story_data = srt_data[0]
            story = StoryContent(
                story_title=story_data.get('story_title', 'Untitled Story'),
                start_time=story_data.get('start_time', '00:00:00,000'),
                end_time=story_data.get('end_time', '00:00:00,000'),
                dialogue=story_data.get('dialogue', [])
            )
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {enhanced_srt_file}")

        logging.info(f"æˆåŠŸè½¬æ¢ä¸ºæ•…äº‹å¯¹è±¡: {story.story_title}")
        return self.generate_from_story(story, video_path, 0)

    def sanitize_filename(self, filename: str) -> str:
        """æ¸…ç†æ–‡ä»¶åï¼Œç§»é™¤ Windows ä¸å…è®¸çš„å­—ç¬¦ï¼Œä¿ç•™ # å­—ç¬¦"""
        # Windows ä¸å…è®¸çš„å­—ç¬¦: < > : " / \ | ? *
        # ä¿ç•™ # å­—ç¬¦ï¼ŒåŒæ—¶ç§»é™¤æ§åˆ¶å­—ç¬¦
        invalid_chars = r'[<>:"/\\|?*\x00-\x1f]'
        sanitized = re.sub(invalid_chars, '', filename)
        # ç§»é™¤å‰åç©ºæ ¼å’Œç‚¹
        sanitized = sanitized.strip('. ')
        # å¦‚æœæ¸…ç†åä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤åç§°
        return sanitized if sanitized else 'untitled'

    def generate_from_story(self, story: StoryContent, video_path: str, story_idx: int = 0, video_id: str = None) -> str:
        """ä» StoryContent å¯¹è±¡ç”Ÿæˆè‰ç¨¿ï¼Œç›´æ¥ä½¿ç”¨å¯¹è±¡"""
        logging.info(f"å¼€å§‹ä¸ºæ•…äº‹ç”Ÿæˆè‰ç¨¿: {story.story_title}")

        # æ¸…ç†æ•…äº‹æ ‡é¢˜ï¼Œç§»é™¤ä¸å®‰å…¨å­—ç¬¦ï¼ˆä¿ç•™å®Œæ•´æ ‡é¢˜ï¼Œä¸æˆªæ–­ï¼‰
        safe_title = self.sanitize_filename(story.story_title.replace(' ', '_'))

        # æ›´æ–°è¾“å‡ºç›®å½•ï¼Œä¸ºæ¯ä¸ªæ•…äº‹åˆ›å»ºç‹¬ç«‹çš„ç›®å½•
        story_output_dir = os.path.join(self.output_dir, f"{video_id}_story_{story_idx + 1}_{safe_title}")

        return self._generate_draft_internal(story, video_path, story_output_dir)

    def _generate_draft_internal(self, story: StoryContent, video_path: str, custom_output_dir: str = None) -> str:
        """å†…éƒ¨è‰ç¨¿ç”Ÿæˆæ–¹æ³•ï¼Œç›´æ¥ä½¿ç”¨ StoryContent å¯¹è±¡"""
        output_dir = custom_output_dir or self.output_dir

        logging.info(f"å¼€å§‹ç”Ÿæˆç®€åŒ–ç‰ˆå¤åˆè‰ç¨¿...")
        logging.info(f"æ¨¡æ¿æ–‡ä»¶: {self.template_file}")
        if self.background_audio_path:
            logging.info(f"èƒŒæ™¯éŸ³é¢‘: {self.background_audio_path}")

        # è¯»å–æ¨¡æ¿æ–‡ä»¶
        with open(self.template_file, 'r', encoding='utf-8') as f:
            draft = json.load(f)

        # ç»Ÿè®¡æœ‰è¯­éŸ³æ–‡ä»¶çš„å¯¹è¯æ•°é‡
        audio_dialogues_count = sum(1 for d in story.dialogue_list if d.audio_path)
        logging.info(f"å¤„ç†æ•…äº‹: {story.story_title}")
        logging.info(f"æ€»å¯¹è¯æ•°: {len(story.dialogue_list)}, æœ‰è¯­éŸ³çš„å¯¹è¯: {audio_dialogues_count}")

        # åˆ›å»ºåµŒå¥—è‰ç¨¿æ•°æ®
        nested_data = self.create_nested_draft_simple(story, video_path)

        # è®¡ç®—æ—¶é—´å’ŒåŠ¨æ€é€Ÿåº¦
        nested_duration = nested_data['duration']
        original_duration_seconds = nested_duration / 1000000.0  # è½¬æ¢ä¸ºç§’

        # åŠ¨æ€è®¡ç®—æ’­æ”¾é€Ÿåº¦
        speed_factor = calculate_speed_factor(original_duration_seconds)

        main_duration = int(nested_duration / speed_factor)

        # 1. æ›´æ–°ä¸»è‰ç¨¿åŸºæœ¬ä¿¡æ¯
        draft['id'] = generate_uuid()
        draft['duration'] = main_duration

        # 1.1. æ›´æ–°ä¸»è½´æ ‡é¢˜æ–‡æœ¬
        self._update_main_title_text(draft, story.story_title, main_duration)

        # 2. æ›¿æ¢åµŒå¥—è‰ç¨¿å†…å®¹
        nested_draft_item = draft['materials']['drafts'][0]
        nested_draft = nested_draft_item['draft']

        # æ›´æ–°åµŒå¥—è‰ç¨¿çš„åŸºæœ¬ä¿¡æ¯
        nested_draft['id'] = generate_uuid()
        nested_draft['duration'] = nested_duration

        # æ›¿æ¢åµŒå¥—è‰ç¨¿çš„ææ–™ - ä½¿ç”¨æ¨¡æ¿å¤åˆ¶
        video_template = nested_draft['materials']['videos'][0] if nested_draft['materials']['videos'] else None
        audio_template = nested_draft['materials']['audios'][0] if nested_draft['materials']['audios'] else None

        # æ¸…ç©ºåŸæœ‰ææ–™
        nested_draft['materials']['videos'] = []
        nested_draft['materials']['audios'] = []

        # å¤åˆ¶å¹¶ä¿®æ”¹è§†é¢‘ææ–™
        for video_mat in nested_data['video_materials']:
            new_video_material = copy.deepcopy(video_template) if video_template else {}
            new_video_material.update({
                "id": video_mat.id,
                "material_name": video_mat.material_name,
                "path": video_mat.path,
                "duration": video_mat.duration,
                "crop": video_mat.crop,
                "local_material_id": str(uuid.uuid4())
            })
            nested_draft['materials']['videos'].append(new_video_material)

        # å¤åˆ¶å¹¶ä¿®æ”¹éŸ³é¢‘ææ–™
        for audio_mat in nested_data['audio_materials']:
            new_audio_material = copy.deepcopy(audio_template) if audio_template else {}
            new_audio_material.update({
                "id": audio_mat.id,
                "name": audio_mat.name,
                "path": audio_mat.path,
                "duration": audio_mat.duration,
                "type": audio_mat.type
            })
            nested_draft['materials']['audios'].append(new_audio_material)

        # æ›¿æ¢åµŒå¥—è‰ç¨¿çš„è½¨é“ç‰‡æ®µ - ä½¿ç”¨æ¨¡æ¿å¤åˆ¶
        video_track = nested_draft['tracks'][0]
        audio_track = nested_draft['tracks'][1]

        # è·å–æ¨¡æ¿ç‰‡æ®µ
        video_seg_template = video_track['segments'][0] if video_track['segments'] else None
        audio_seg_template = audio_track['segments'][0] if audio_track['segments'] else None

        # æ¸…ç©ºç°æœ‰ç‰‡æ®µ
        video_track['segments'] = []
        audio_track['segments'] = []

        # å¤åˆ¶å¹¶ä¿®æ”¹è§†é¢‘ç‰‡æ®µ
        for video_seg in nested_data['video_segments']:
            new_video_seg = copy.deepcopy(video_seg_template) if video_seg_template else {}
            new_video_seg.update({
                "id": video_seg.id,
                "material_id": video_seg.material_id,
                "source_timerange": video_seg.source_timerange,
                "target_timerange": video_seg.target_timerange,
                "speed": video_seg.speed,
                "volume": video_seg.volume
            })
            # æ›´æ–°clipä¸­çš„scale
            if 'clip' in new_video_seg:
                new_video_seg['clip']['scale'] = video_seg.clip['scale']
            # ğŸ†• ä¿ç•™æ¨¡æ¿ä¸­çš„ extra_material_refs (éŸ³æ•ˆå¼•ç”¨)
            # å¦‚æœæ¨¡æ¿æœ‰ extra_material_refs,åˆ™ä¿ç•™å®ƒ
            if video_seg_template and 'extra_material_refs' in video_seg_template:
                new_video_seg['extra_material_refs'] = video_seg_template['extra_material_refs']
            video_track['segments'].append(new_video_seg)

        # å¤åˆ¶å¹¶ä¿®æ”¹éŸ³é¢‘ç‰‡æ®µ
        for audio_seg in nested_data['audio_segments']:
            new_audio_seg = copy.deepcopy(audio_seg_template) if audio_seg_template else {}
            new_audio_seg.update({
                "id": audio_seg.id,
                "material_id": audio_seg.material_id,
                "source_timerange": audio_seg.source_timerange,
                "target_timerange": audio_seg.target_timerange,
                "speed": audio_seg.speed,
                "volume": audio_seg.volume
            })
            # ğŸ†• ä¿ç•™æ¨¡æ¿ä¸­çš„ extra_material_refs (éŸ³æ•ˆå¼•ç”¨)
            # å¦‚æœæ¨¡æ¿æœ‰ extra_material_refs,åˆ™ä¿ç•™å®ƒ
            if audio_seg_template and 'extra_material_refs' in audio_seg_template:
                new_audio_seg['extra_material_refs'] = audio_seg_template['extra_material_refs']
            audio_track['segments'].append(new_audio_seg)

        # å¤„ç†å­—å¹•è½¨é“
        self._add_subtitle_tracks(nested_draft, nested_data)

        # 3. æ›´æ–°ä¸»è‰ç¨¿çš„å¤åˆè§†é¢‘ææ–™æ—¶é•¿
        composite_video = draft['materials']['videos'][0]
        composite_video['duration'] = nested_duration

        # 4. æ›´æ–°ä¸»è‰ç¨¿çš„è§†é¢‘è½¨é“æ—¶é—´
        main_video_segment = draft['tracks'][0]['segments'][0]
        main_video_segment['source_timerange']['duration'] = nested_duration
        main_video_segment['target_timerange']['duration'] = main_duration
        main_video_segment['speed'] = speed_factor

        # 5. å¤„ç†èƒŒæ™¯éŸ³é¢‘ - ä½¿ç”¨æ·±åº¦æ‹·è´
        if self.background_audio_path:
            # åˆ›å»ºèƒŒæ™¯éŸ³é¢‘å¯¹è±¡
            bg_audio = AudioMaterial(
                material_id=generate_uuid(),
                name=os.path.basename(self.background_audio_path),
                path=f"##_draftpath_placeholder_0E685133-18CE-45ED-8CB8-2904A212EC80_##/materials/{os.path.basename(self.background_audio_path)}",
                duration=int(get_audio_duration(self.background_audio_path) * 1000000),
                audio_type="sound"
            )

            # è·å–æ¨¡æ¿éŸ³é¢‘ææ–™å¹¶æ·±åº¦æ‹·è´
            main_audio_template = draft['materials']['audios'][0] if draft['materials']['audios'] else None
            if main_audio_template:
                new_bg_audio_material = copy.deepcopy(main_audio_template)
                new_bg_audio_material.update({
                    "id": bg_audio.id,
                    "name": bg_audio.name,
                    "path": bg_audio.path,
                    "duration": bg_audio.duration,
                    "type": bg_audio.type
                })
                draft['materials']['audios'].append(new_bg_audio_material)

            # è·å–æ¨¡æ¿éŸ³é¢‘ç‰‡æ®µå¹¶æ·±åº¦æ‹·è´
            main_audio_seg_template = draft['tracks'][2]['segments'][0] if draft['tracks'][2]['segments'] else None
            if main_audio_seg_template:
                new_bg_audio_segment = copy.deepcopy(main_audio_seg_template)
                new_bg_audio_segment.update({
                    "id": generate_uuid(),
                    "material_id": bg_audio.id,
                    "source_timerange": {"duration": main_duration, "start": 0},
                    "target_timerange": {"duration": main_duration, "start": 0},
                    "speed": 1.0
                })
                draft['tracks'][2]['segments'] = [new_bg_audio_segment]
            else:
                # å¦‚æœæ²¡æœ‰æ¨¡æ¿ï¼Œæ¸…ç©ºéŸ³é¢‘è½¨é“
                draft['tracks'][2]['segments'] = []
        else:
            # æ¸…ç©ºéŸ³é¢‘è½¨é“
            draft['tracks'][2]['segments'] = []

        # 6. å¤åˆ¶æ–‡ä»¶å’Œä¿å­˜
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        materials_dir = output_path / "materials"
        materials_dir.mkdir(exist_ok=True)

        # ç›´æ¥å¤åˆ¶åŸå§‹è§†é¢‘æ–‡ä»¶
        video_src = Path(video_path)
        video_dest = materials_dir / os.path.basename(video_path)

        if not video_dest.exists():
            shutil.copy2(video_src, video_dest)
            logging.info(f"å¤åˆ¶è§†é¢‘æ–‡ä»¶: {video_dest}")
        else:
            logging.info(f"è§†é¢‘æ–‡ä»¶å·²å­˜åœ¨: {video_dest}")

        # å¤åˆ¶éŸ³é¢‘æ–‡ä»¶
        for dialogue in story.dialogue_list:
            if dialogue.audio_path:
                audio_src = Path(dialogue.audio_path)
                audio_dest = materials_dir / os.path.basename(dialogue.audio_path)
                if not audio_dest.exists():
                    shutil.copy2(audio_src, audio_dest)
                    logging.info(f"å¤åˆ¶éŸ³é¢‘æ–‡ä»¶: {audio_dest}")

        # å¤åˆ¶èƒŒæ™¯éŸ³é¢‘
        if self.background_audio_path:
            bg_audio_src = Path(self.background_audio_path)
            bg_audio_dest = materials_dir / os.path.basename(self.background_audio_path)
            if not bg_audio_dest.exists():
                shutil.copy2(bg_audio_src, bg_audio_dest)
                logging.info(f"å¤åˆ¶èƒŒæ™¯éŸ³é¢‘æ–‡ä»¶: {bg_audio_dest}")

        # å¤åˆ¶æ¨¡æ¿è®¾ç½®æ–‡ä»¶
        settings_src = Path(DEFAULT_TEMPLATE_SETTINGS)
        if settings_src.exists():
            settings_dest = output_path / "draft_settings"
            if not settings_dest.exists():
                shutil.copy2(settings_src, settings_dest)
                logging.info(f"å¤åˆ¶æ¨¡æ¿è®¾ç½®æ–‡ä»¶: {settings_dest}")

        # å¤åˆ¶æ¨¡æ¿ä¿¡æ¯æ–‡ä»¶
        info_src = Path(DEFAULT_TEMPLATE_INFO_FILE)
        if info_src.exists():
            info_dest = output_path / "draft_meta_info.json"
            if not info_dest.exists():
                shutil.copy2(info_src, info_dest)
                logging.info(f"å¤åˆ¶æ¨¡æ¿ä¿¡æ¯æ–‡ä»¶: {info_dest}")

        # ä¿å­˜è‰ç¨¿æ–‡ä»¶
        draft_file = output_path / "draft_content.json"
        with open(draft_file, 'w', encoding='utf-8') as f:
            json.dump(draft, f, ensure_ascii=False, separators=(',', ':'))

        logging.info(f"âœ“ ç®€åŒ–ç‰ˆå¤åˆè‰ç¨¿ç”Ÿæˆå®Œæˆ: {draft_file}")
        return str(draft_file)


# ä¸ºäº†å‘åå…¼å®¹ï¼Œä¿ç•™åŸæœ‰çš„å‡½æ•°æ¥å£
def generate_simple_composite_draft(enhanced_srt_file, video_path, template_file, output_dir,
                                   scale_x=1.0, scale_y=1.0, gap=0, blur_strength=0.375,
                                   speed_factor=None, background_audio_path=None):
    """å‘åå…¼å®¹çš„å‡½æ•°æ¥å£ï¼Œspeed_factor å‚æ•°å·²åºŸå¼ƒï¼Œæ”¹ä¸ºåŠ¨æ€è®¡ç®—"""
    if speed_factor is not None:
        logging.info(f"âš ï¸  è­¦å‘Š: speed_factor å‚æ•°å·²åºŸå¼ƒï¼Œç°åœ¨æ ¹æ®è§†é¢‘æ—¶é•¿åŠ¨æ€è®¡ç®—é€Ÿåº¦")

    generator = DraftGenerator(
        template_file=template_file,
        output_dir=output_dir,
        scale_x=scale_x,
        scale_y=scale_y,
        gap=gap,
        blur_strength=blur_strength,
        background_audio_path=background_audio_path
    )
    return generator.generate_from_file(enhanced_srt_file, video_path)


def main():
    if len(sys.argv) < 3:
        logging.info(
            "ç”¨æ³•: python draft_gen.py <enhanced_srt_file> <video_path>")
        sys.exit(1)

    enhanced_srt_file = sys.argv[1]
    video_path = sys.argv[2]

    try:
        # ä½¿ç”¨æ–°çš„é¢å‘å¯¹è±¡æ¥å£
        generator = DraftGenerator()
        result = generator.generate_from_file(enhanced_srt_file, video_path)
        logging.info(f"ç®€åŒ–ç‰ˆå¤åˆè‰ç¨¿ç”ŸæˆæˆåŠŸ: {result}")
    except Exception as e:
        logging.info(f"ç”Ÿæˆç®€åŒ–ç‰ˆå¤åˆè‰ç¨¿å¤±è´¥: {e}")
        import traceback
        traceback.logging.info_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()