
from newapi_client import GeminiClient
from tts_client_new import TTSClient
from draft_gen import DraftGenerator
from dl_splitter_video import VideoDownloader
from srt_generate import JSONSubtitleGenerator
from data_models import StoryDialogue, StoryContent, VideoSegment, VideoProject
import sys
import json
import os
from datetime import datetime
from typing import List, Dict, Optional
import logging



PROJECT_CACHE_DIR = './output/project_cache'

sys_prompt = """
ç”¨æˆ·è¾“å…¥çš„æ˜¯ä¸€ä¸ªåŒ…å« index å­—æ®µçš„ JSON æ•°ç»„ï¼ˆç±»ä¼¼ SRT æ ¼å¼ï¼‰ã€‚
ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®æ•…äº‹æƒ…èŠ‚å¯¹å†…å®¹è¿›è¡Œåˆ‡å‰²ï¼Œè¾“å‡ºæ ¼å¼ä¸ºçº¯ JSONã€‚

**æ ¸å¿ƒè¦æ±‚**ï¼š
1. æ¯ä¸ªæ•…äº‹çš„ dialogue ä½¿ç”¨ source_indices æ•°ç»„å¼•ç”¨åŸå§‹è¾“å…¥çš„ indexï¼ˆé‡è¦ï¼å¿…é¡»ä½¿ç”¨ source_indicesï¼‰
2. åˆ‡å‰²çš„æ•…äº‹è¦å®Œæ•´ï¼Œæ—¶é•¿æ§åˆ¶åœ¨ 1.5 åˆ†é’Ÿä»¥å†…
3. ç¿»è¯‘ä¸ºç®€æ´è‹±æ–‡ï¼Œç¬¦åˆç¾å›½æ–‡åŒ–ï¼ˆäººååœ°åæœ¬åœ°åŒ–ï¼‰
4. æ ‡é¢˜å¸å¼•åŠ›å¼ºï¼ŒåŒ…å«åŸä½œæ ‡ç­¾ï¼Œä¸è¶…è¿‡ 90 å­—ç¬¦
5. ä¸€ä¸ª dialogue å¯ä»¥åˆå¹¶å¤šä¸ªåŸå§‹æ–‡æœ¬ï¼ˆé€šè¿‡ source_indices å¼•ç”¨å¤šä¸ª indexï¼‰
6. ä¿æŒåŸå§‹è¾“å…¥çš„ index ä¸å˜ï¼Œä»…é€šè¿‡ source_indices å¼•ç”¨

**è¾“å‡ºæ ¼å¼ç¤ºä¾‹**ï¼š
[
  {
    "story_title": "Bart's Epic Fail Becomes Victory #simpsons",
    "start_index": 1,
    "end_index": 25,
    "dialogue": [
      {
        "chinese": "åˆå¹¶åçš„ä¸­æ–‡æ–‡æœ¬ï¼ˆå¯ä»¥æ¦‚æ‹¬å¤šå¥ï¼‰",
        "english": "Merged English text for multiple source lines",
        "source_indices": [1, 2, 3]
      },
      {
        "chinese": "å¦ä¸€æ®µå¯¹è¯",
        "english": "Another dialogue segment",
        "source_indices": [4, 5]
      }
    ]
  }
]

**é‡è¦æç¤º**ï¼š
- å¿…é¡»ä½¿ç”¨ source_indices å­—æ®µï¼Œä¸è¦ä½¿ç”¨ start/end å­—æ®µ
- source_indices æ˜¯ä¸€ä¸ªæ•°ç»„ï¼ŒåŒ…å«å¼•ç”¨çš„åŸå§‹ index
- åˆå¹¶å¤šä¸ªå¥å­æ—¶ï¼Œchinese å’Œ english åº”è¯¥æ˜¯åˆå¹¶åçš„å®Œæ•´å†…å®¹
"""

ai_analysis_dir = "./output/ai_analysis/"
if not os.path.exists(ai_analysis_dir):
    os.makedirs(ai_analysis_dir)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(filename)s:%(lineno)d - %(message)s'
)
logger = logging.getLogger(__name__)

class ShortStoryGenerator:
    def __init__(self, max_duration_minutes: int = 10, output_dir: str = "./output/org_materials"):
        self.client = GeminiClient()
        self.tts_client = TTSClient()
        self.max_duration_minutes = max_duration_minutes
        self.output_dir = output_dir

        # åˆå§‹åŒ–ä¸‹è½½å™¨å’ŒSRTç”Ÿæˆå™¨
        self.video_downloader = VideoDownloader(
            max_duration_minutes=max_duration_minutes,
            output_dir=output_dir
        )
        self.srt_generator = JSONSubtitleGenerator(output_dir="./output")

        # åˆå§‹åŒ–è‰ç¨¿ç”Ÿæˆå™¨
        self.draft_generator = DraftGenerator()

    def generate(self, url: str) -> Optional[VideoProject]:
        logging.info(f"ğŸ¬ å¼€å§‹å¤„ç†è§†é¢‘URL: {url}")

        try:
            # ç¬¬ä¸€æ­¥ï¼šä¸‹è½½è§†é¢‘å’Œåˆ‡å‰²
            logging.info("ğŸ“¥ ç¬¬ä¸€æ­¥ï¼šä¸‹è½½å¹¶åˆ‡å‰²è§†é¢‘...")
            video_segments_data = self.video_downloader.process_video(url)
            if not video_segments_data:
                logging.info("âŒ è§†é¢‘ä¸‹è½½å¤±è´¥")
                return None

            # åˆ›å»ºè§†é¢‘é¡¹ç›®å¯¹è±¡
            video_project = VideoProject(url)

            # ç¬¬äºŒæ­¥ï¼šä¸ºæ¯ä¸ªè§†é¢‘æ®µç”ŸæˆSRTæ–‡ä»¶
            logging.info(f"ğŸµ ç¬¬äºŒæ­¥ï¼šä¸º {len(video_segments_data)} ä¸ªè§†é¢‘æ®µç”ŸæˆSRTæ–‡ä»¶...")
            for i, segment_data in enumerate(video_segments_data):
                logging.info(f"\nå¤„ç†è§†é¢‘æ®µ {i+1}/{len(video_segments_data)}")

                # åˆ›å»ºVideoSegmentå¯¹è±¡
                video_segment = VideoSegment(
                    url=url,
                    segment_index=segment_data['segment_index'],
                    start_time=segment_data['start_time'],
                    duration=segment_data['duration'],
                    org_video_file_path=segment_data['org_video_file_path'],
                    org_audio_file_path=segment_data['org_audio_file_path']
                )

                # ç”ŸæˆSRTæ–‡ä»¶
                srt_file_path, sotry_num = self.generate_srt_for_segment(video_segment)
                if srt_file_path:
                    video_segment.srt_file_path = srt_file_path

                    # ç¬¬ä¸‰æ­¥ï¼šåˆ†æSRTæ–‡ä»¶ç”Ÿæˆæ•…äº‹
                    logging.info(f"ğŸ“– ç¬¬ä¸‰æ­¥ï¼šåˆ†æSRTæ–‡ä»¶ç”Ÿæˆæ•…äº‹...")
                    stories = self.ai_analysis_story(srt_file_path, sotry_num)
                    if stories:
                        video_segment.stories = stories

                        # ç¬¬å››æ­¥ï¼šä¸ºæ¯ä¸ªæ•…äº‹ç”Ÿæˆè¯­éŸ³å’Œè‰ç¨¿
                        logging.info(f"ğŸ¤ ç¬¬å››æ­¥ï¼šä¸º {len(stories)} ä¸ªæ•…äº‹ç”Ÿæˆè¯­éŸ³å’Œè‰ç¨¿...")
                        for story_idx, story in enumerate(stories):
                            self.process_story_for_segment(story, story_idx, video_segment)

                video_project.add_segment(video_segment)

            # ä¿å­˜é¡¹ç›®ç»“æœ
            self.save_project_to_cache(video_project)

            logging.info(f"âœ… è§†é¢‘å¤„ç†å®Œæˆï¼å…±å¤„ç† {len(video_project.segments)} ä¸ªè§†é¢‘æ®µ")
            return video_project

        except Exception as e:
            logging.info(f"âŒ å¤„ç†å¤±è´¥: {e}")
            import traceback
            traceback.logging.info_exc()
            return None

    def generate_srt_for_segment(self, video_segment: VideoSegment):
        """ä¸ºè§†é¢‘æ®µç”ŸæˆSRTæ–‡ä»¶"""
        try:
            logging.info(f"ğŸµ ä¸ºè§†é¢‘æ®µ {video_segment.segment_index} ç”ŸæˆSRTæ–‡ä»¶...")

            
            # ä½¿ç”¨éŸ³é¢‘æ–‡ä»¶è·¯å¾„ç”ŸæˆSRT
            srt_file_path , story_num = self.srt_generator.transcribe(video_segment.org_audio_file_path)

            if srt_file_path and os.path.exists(srt_file_path):
                logging.info(f"âœ… SRTæ–‡ä»¶ç”ŸæˆæˆåŠŸ: {srt_file_path}")
                return srt_file_path, story_num
            else:
                logging.info(f"âŒ SRTæ–‡ä»¶ç”Ÿæˆå¤±è´¥")
                return None

        except Exception as e:
            logging.info(f"âŒ SRTæ–‡ä»¶ç”Ÿæˆå¼‚å¸¸: {e}")
            return None

    def process_story_for_segment(self, story: StoryContent, story_idx: int, video_segment: VideoSegment):
        video_id = video_segment.url.split("/")[-1].split("?")[0]
        """ä¸ºè§†é¢‘æ®µä¸­çš„æ•…äº‹ç”Ÿæˆè¯­éŸ³å’Œè‰ç¨¿"""
        try:
            logging.info(f"ğŸ¤ å¤„ç†è§†é¢‘æ®µ {video_id}:{video_segment.segment_index} çš„æ•…äº‹ {story_idx + 1}: {story.story_title}")

            # åˆ›å»ºè¾“å‡ºç›®å½•
            base_filename = f"{video_id}_segment_{video_segment.segment_index}"
            output_dir = f"./output/tmp_voice/{base_filename}"
            if not os.path.exists(output_dir):
                os.makedirs(output_dir)

            # ç”Ÿæˆè¯­éŸ³
            processed_story = self.process_single_story_audio(story, story_idx, output_dir)

            # ç”Ÿæˆè‰ç¨¿æ–‡ä»¶
            self.generate_draft_file(processed_story, story_idx, video_segment.org_video_file_path, video_id)

            logging.info(f"âœ… æ•…äº‹å¤„ç†å®Œæˆ: {story.story_title}")

        except Exception as e:
            logging.info(f"âŒ æ•…äº‹å¤„ç†å¤±è´¥: {e}")

    def save_project_to_cache(self, video_project: VideoProject) -> str:
        """ä¿å­˜è§†é¢‘é¡¹ç›®åˆ°ç¼“å­˜æ–‡ä»¶"""
        try:
            # ç”Ÿæˆç¼“å­˜æ–‡ä»¶è·¯å¾„
            url_safe = video_project.url.split("/")[-1].split("?")[0]
            cache_file = f"{PROJECT_CACHE_DIR}/{url_safe}_{int(video_project.project_created_time.timestamp())}.json"

            # ä¿å­˜åˆ°æ–‡ä»¶
            with open(cache_file, 'w', encoding='utf-8') as f:
                json.dump(video_project.to_dict(), f, ensure_ascii=False, indent=2)

            logging.info(f"ğŸ’¾ é¡¹ç›®å·²ç¼“å­˜åˆ°: {cache_file}")
            return cache_file

        except Exception as e:
            logging.info(f"âŒ é¡¹ç›®ç¼“å­˜å¤±è´¥: {e}")
            return None

    def ai_analysis_story(self, srt_file, story_num: int) -> List[StoryContent]:
        """
        AIåˆ†ææ•…äº‹æ–¹æ³• - å…ˆæ£€æŸ¥ç¼“å­˜ï¼Œæ²¡æœ‰ç¼“å­˜åˆ™è°ƒç”¨AIç”Ÿæˆ
        """
        # ç”Ÿæˆç¼“å­˜æ–‡ä»¶è·¯å¾„
        base_filename = os.path.splitext(os.path.basename(srt_file))[0]
        cache_file = os.path.join(ai_analysis_dir, f"{base_filename}.json")

        # 1. å…ˆæ£€æŸ¥ç¼“å­˜æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if os.path.exists(cache_file):
            logging.info(f"ğŸ’¾ å‘ç°ç¼“å­˜æ–‡ä»¶ï¼ŒåŠ è½½ä¸­: {cache_file}")
            try:
                with open(cache_file, "r", encoding="utf-8") as f:
                    analysis_result = f.read()

                # è§£æå¹¶è¿”å›å¯¹è±¡
                stories = self.parse_analysis_result_obj(analysis_result, srt_file)
                if stories:
                    logging.info(f"âœ… ä»ç¼“å­˜åŠ è½½äº† {len(stories)} ä¸ªæ•…äº‹")
                    return stories
                else:
                    logging.info("âš ï¸ ç¼“å­˜æ–‡ä»¶æŸåï¼Œå°†é‡æ–°ç”Ÿæˆ")
            except Exception as e:
                logging.info(f"âš ï¸ ç¼“å­˜æ–‡ä»¶è¯»å–å¤±è´¥: {e}ï¼Œå°†é‡æ–°ç”Ÿæˆ")

        # 2. æ²¡æœ‰ç¼“å­˜æˆ–ç¼“å­˜æŸåï¼Œè°ƒç”¨AIç”Ÿæˆ
        logging.info("ğŸ¤– æ­£åœ¨è°ƒç”¨AIåˆ†æ...")

        # åŠ è½½srtæ–‡ä»¶
        with open(srt_file, "r", encoding="utf-8") as f:
            data = json.loads(f.read())
            # ğŸ”‘ ä¿ç•™ time å­—æ®µï¼Œä½†ä¸ºAIè¾“å…¥åˆ›å»ºä¸€ä¸ªç®€åŒ–ç‰ˆæœ¬ï¼ˆåªä¿ç•™ index å’Œ textï¼‰
            ai_input_data = []
            for item in data:
                ai_input_data.append({
                    'index': item['index'],
                    'text': item['text']
                })
        input_date = json.dumps(ai_input_data)

        text = f"ç”Ÿæˆæ•…äº‹ç‰‡æ®µä¸º: {story_num} ä¸ª \n {input_date}"

        # è°ƒç”¨AIåˆ†æ
        analysis_result = self.client.analyze_text(text, sys_prompt)

        if not analysis_result:
            logging.info("âŒ AIåˆ†æè¿”å›ç©ºç»“æœ")
            return []

        # æ¸…ç†ç»“æœæ ¼å¼
        if analysis_result.startswith('`'):
            analysis_result = analysis_result.replace('`', '').replace('json', '')

        # 3. ç¼“å­˜AIåˆ†æç»“æœ
        try:
            with open(cache_file, "w", encoding="utf-8") as f:
                f.write(analysis_result)
            logging.info(f"ğŸ’¾ AIåˆ†æç»“æœå·²ç¼“å­˜åˆ°: {cache_file}")
        except Exception as e:
            logging.info(f"âš ï¸ ç¼“å­˜å¤±è´¥: {e}")

        # 4. è§£æå¹¶è¿”å›å¯¹è±¡
        stories = self.parse_analysis_result_obj(analysis_result,srt_file)
        if stories:
            logging.info(f"âœ… AIåˆ†æå®Œæˆï¼Œè·å–åˆ° {len(stories)} ä¸ªæ•…äº‹")
        else:
            logging.info("âŒ AIåˆ†æç»“æœè§£æå¤±è´¥")

        return stories

    def parse_analysis_result_obj(self, analysis_result: str, srt_file: str) -> List[StoryContent]:
        """è§£æAIåˆ†æç»“æœä¸ºå¯¹è±¡ - æ”¯æŒ source_indices æ ¼å¼"""
        try:
            # 1. åŠ è½½ SRT JSON åˆ›å»ºç´¢å¼•æ˜ å°„
            with open(srt_file, 'r', encoding='utf-8') as f:
                srt_data = json.load(f)

            # åˆ›å»º index â†’ srt_item çš„æ˜ å°„
            srt_map = {item['index']: item for item in srt_data}
            logging.info(f"ğŸ“– åŠ è½½äº† {len(srt_map)} æ¡ SRT è®°å½•")

            # 2. æ¸…ç†å¯èƒ½çš„markdownæ ¼å¼
            clean_result = analysis_result.strip()
            if clean_result.startswith('json'):
                clean_result = clean_result[4:].strip()
            if clean_result.startswith('```'):
                clean_result = clean_result.replace('```', '')

            # 3. è§£æJSON
            stories_data = json.loads(clean_result)

            # 4. è½¬æ¢ä¸ºå¯¹è±¡
            stories = []
            for story_data in stories_data:
                # å¤„ç†æ¯ä¸ª dialogue
                dialogue_list = []
                for idx, dialogue_data in enumerate(story_data['dialogue']):
                    # ğŸ”‘ æ ¹æ® source_indices è¿˜åŸ video_segments
                    video_segments = []
                    source_indices = dialogue_data.get('source_indices', [])

                    if source_indices:
                        # æ–°æ ¼å¼ï¼šä½¿ç”¨ source_indices
                        logging.info(f"  ğŸ”— å¤„ç† dialogue {idx}ï¼Œsource_indices: {source_indices}")
                        for srt_idx in source_indices:
                            if srt_idx in srt_map:
                                time_str = srt_map[srt_idx]['time']  # "00:00:00,000 --> 00:00:02,000"
                                if ' --> ' in time_str:
                                    start, end = time_str.split(' --> ')
                                    video_segments.append({
                                        'start': start.strip(),
                                        'end': end.strip()
                                    })
                                else:
                                    logging.warning(f"  âš ï¸ SRT index {srt_idx} æ—¶é—´æ ¼å¼å¼‚å¸¸: {time_str}")
                            else:
                                logging.warning(f"  âš ï¸ SRT index {srt_idx} ä¸å­˜åœ¨")
                    else:
                        # å…¼å®¹æ—§æ ¼å¼ï¼šä½¿ç”¨ start/end å­—æ®µ
                        if 'start' in dialogue_data and 'end' in dialogue_data:
                            logging.info(f"  ğŸ“Œ ä½¿ç”¨æ—§æ ¼å¼ start/end")
                            video_segments.append({
                                'start': dialogue_data['start'],
                                'end': dialogue_data['end']
                            })
                        else:
                            logging.warning(f"  âš ï¸ dialogue {idx} ç¼ºå°‘ source_indices å’Œ start/end")

                    # åˆ›å»º dialogue å­—å…¸ï¼ˆç”¨äº StoryContent åˆå§‹åŒ–ï¼‰
                    dialogue_dict = {
                        'index': idx,
                        'video_segments': video_segments,
                        'chinese': dialogue_data.get('chinese', ''),
                        'english': dialogue_data.get('english', 'God bless you')
                    }
                    dialogue_list.append(dialogue_dict)

                # åˆ›å»º StoryContentï¼ˆä¼šè‡ªåŠ¨è½¬æ¢ä¸º StoryDialogue å¯¹è±¡ï¼‰
                story = StoryContent(
                    story_title=story_data['story_title'],
                    start_index=story_data.get('start_index', 0),
                    end_index=story_data.get('end_index', 0),
                    dialogue=dialogue_list
                )
                stories.append(story)

            logging.info(f"âœ… æˆåŠŸè§£æ {len(stories)} ä¸ªæ•…äº‹")
            return stories

        except Exception as e:
            logging.error(f"âŒ è§£æå¯¹è±¡å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return []

    def process_single_story_audio(self, story: StoryContent, story_idx: int, output_dir: str) -> StoryContent:
        """ä¸ºå•ä¸ªæ•…äº‹ç”Ÿæˆè¯­éŸ³ - å¸¦ç¼“å­˜é€»è¾‘"""
        logging.info(f"ğŸµ å¼€å§‹ä¸ºæ•…äº‹ç”Ÿæˆè¯­éŸ³: {story.story_title}")

        # ä¸ºæ¯ä¸ªå¯¹è¯ç”Ÿæˆè¯­éŸ³
        for dialogue in story.dialogue_list:
            try:
                # ç”ŸæˆéŸ³é¢‘æ–‡ä»¶è·¯å¾„
                audio_filename = f"story_{story_idx + 1}_dialogue_{dialogue.index}.mp3"
                audio_path = os.path.join(output_dir, audio_filename)
                srt_filename = f"story_{story_idx + 1}_dialogue_{dialogue.index}.srt"
                srt_path = os.path.join(output_dir, srt_filename)

                # 1. æ£€æŸ¥è¯­éŸ³æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
                if os.path.exists(audio_path):
                    logging.info(f"  ğŸ’¾ å‘ç°ç¼“å­˜éŸ³é¢‘: {audio_filename}")

                    # æ£€æŸ¥æ–‡ä»¶å¤§å°æ˜¯å¦æ­£å¸¸ï¼ˆå¤§äº1KBï¼‰
                    if os.path.getsize(audio_path) > 1024:
                        # æ›´æ–°å¯¹è±¡ä¸­çš„è·¯å¾„ä¿¡æ¯
                        dialogue.audio_path = audio_path

                        # æ£€æŸ¥å­—å¹•æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                        if os.path.exists(srt_path):
                            dialogue.srt_path = srt_path
                        else:
                            dialogue.srt_path = None

                        logging.info(f"  âœ… ä½¿ç”¨ç¼“å­˜éŸ³é¢‘: {audio_filename}")
                        continue
                    else:
                        logging.info(f"  âš ï¸ ç¼“å­˜æ–‡ä»¶æŸåï¼ˆå¤ªå°ï¼‰ï¼Œå°†é‡æ–°ç”Ÿæˆ")
                        # åˆ é™¤æŸåçš„æ–‡ä»¶
                        try:
                            os.remove(audio_path)
                        except:
                            pass

                # 2. ç”Ÿæˆæ–°çš„è¯­éŸ³æ–‡ä»¶
                logging.info(f"  ğŸ¤ ç”Ÿæˆå¯¹è¯ {dialogue.index}: {dialogue.english[:50]}...")

                # è°ƒç”¨TTSç”Ÿæˆè¯­éŸ³
                generated_srt_path = self.tts_client.generate_and_save_audio(
                    text=dialogue.english,
                    output_file=audio_path,
                    voice="zh-HK-HiuGaaiNeural"
                )

                # 3. éªŒè¯ç”Ÿæˆçš„æ–‡ä»¶
                if os.path.exists(audio_path) and os.path.getsize(audio_path) > 1024:
                    # æ›´æ–°å¯¹è±¡ä¸­çš„è·¯å¾„ä¿¡æ¯
                    dialogue.audio_path = audio_path
                    dialogue.srt_path = generated_srt_path if generated_srt_path else None

                    logging.info(f"  âœ… è¯­éŸ³ç”Ÿæˆå®Œæˆ: {audio_filename}")
                else:
                    logging.info(f"  âŒ è¯­éŸ³æ–‡ä»¶ç”Ÿæˆå¼‚å¸¸")
                    dialogue.audio_path = None
                    dialogue.srt_path = None

            except Exception as e:
                logging.info(f"  âŒ ç”Ÿæˆè¯­éŸ³å¤±è´¥: {e}")
                dialogue.audio_path = None
                dialogue.srt_path = None

        logging.info(f"âœ… æ•…äº‹ '{story.story_title}' è¯­éŸ³å¤„ç†å®Œæˆ!")
        return story

    def generate_draft_file(self, story: 'StoryContent', story_idx: int, video_path: str = None, video_id: str = None) -> str:
        """ä¸ºå•ä¸ªæ•…äº‹ç”Ÿæˆè‰ç¨¿æ–‡ä»¶"""
        try:
            logging.info(f"ğŸ“ å¼€å§‹ä¸ºæ•…äº‹ç”Ÿæˆè‰ç¨¿: {story.story_title}")

            # ä½¿ç”¨ DraftGenerator çš„ generate_from_story æ–¹æ³•
            if not os.path.exists(video_path):
                logging.info(f"âŒ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
                return None
            
            draft_file = self.draft_generator.generate_from_story(
                story=story,
                video_path=video_path,
                story_idx=story_idx,
                video_id=video_id
            )

            logging.info(f"âœ… è‰ç¨¿æ–‡ä»¶ç”Ÿæˆå®Œæˆ: {draft_file}")
            return draft_file

        except Exception as e:
            logging.info(f"âŒ ç”Ÿæˆè‰ç¨¿æ–‡ä»¶å¤±è´¥: {e}")
            import traceback
            traceback.logging.info_exc()
            return None

    def save_stories_to_cache(self, stories: List[StoryContent], srt_file: str) -> str:
        """å°†å¤„ç†ç»“æœç¼“å­˜åˆ°æœ¬åœ°æ–‡ä»¶"""
        try:
            # ç”Ÿæˆç¼“å­˜æ–‡ä»¶è·¯å¾„
            base_filename = os.path.splitext(os.path.basename(srt_file))[0]
            cache_file = f"./output/{base_filename}_processed_stories.json"

            # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„å­—å…¸æ ¼å¼
            cache_data = {
                'source_file': srt_file,
                'processed_time': datetime.now().isoformat(),
                'stories': [story.to_dict() for story in stories]
            }

            # ä¿å­˜åˆ°æ–‡ä»¶
            with open(cache_file, 'w', encoding='utf-8') as f:
                json.dump(cache_data, f, ensure_ascii=False, indent=2)

            logging.info(f"ğŸ’¾ ç»“æœå·²ç¼“å­˜åˆ°: {cache_file}")
            return cache_file

        except Exception as e:
            logging.info(f"âŒ ç¼“å­˜å¤±è´¥: {e}")
            return None

if __name__ == "__main__":
    if len(sys.argv) < 2:
        logging.info("Usage: python short_story_generator.py <video_url> [max_duration_minutes] [output_dir]")
        logging.info("Example: python short_story_generator.py 'https://www.bilibili.com/video/BV1abc123def' 10 './output/org_materials'")
        sys.exit(1)

    video_url = sys.argv[1]
    max_duration_minutes = int(sys.argv[2]) if len(sys.argv) > 2 else 10
    output_dir = sys.argv[3] if len(sys.argv) > 3 else "./output/org_materials"

    generator = ShortStoryGenerator(
        max_duration_minutes=max_duration_minutes,
        output_dir=output_dir
    )
    result = generator.generate(video_url)

    if result:
        logging.info(f"\nğŸ‰ å¤„ç†å®Œæˆï¼é¡¹ç›®åŒ…å« {len(result.segments)} ä¸ªè§†é¢‘æ®µ")
        for i, segment in enumerate(result.segments, 1):
            logging.info(f"æ®µ {i}: {len(segment.stories)} ä¸ªæ•…äº‹ï¼ŒSRTæ–‡ä»¶: {segment.srt_file_path}")
    else:
        logging.info("âŒ å¤„ç†å¤±è´¥")
        sys.exit(1)

